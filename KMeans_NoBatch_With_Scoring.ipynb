{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86e5efba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import contractions\n",
    "\n",
    "from tqdm import tqdm\n",
    "from nltk import tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm import tqdm\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa8ff0a",
   "metadata": {},
   "source": [
    "# KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91658039",
   "metadata": {},
   "source": [
    "Below is an implemented KMeans algorithm on Word2Vec embeddings of the WikiHow article data. KMeans is an unsupervised learning algorithm, meaning we do not care about the \"Summary\" columns during training. The pipeline is summarized as follows:\n",
    "- Preprocess Text (Remove stopwords, short words, punctuation, etc.)\n",
    "- Tokenize Data\n",
    "- Embed data into Word2Vec\n",
    "- Pass embedded vectors into KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66db768d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Here we set text to lower case, remove plurals, \n",
    "    expand contractions, remove punctuation, remove stopwords, and remove short words \n",
    "    (could also remove parentheticals)\"\"\"\n",
    "\n",
    "stop = set(stopwords.words('english'))\n",
    "def clean_text(text):\n",
    "    ret = text.lower()\n",
    "    ret = contractions.fix(text)\n",
    "    ret = re.sub(r'\\([^)]*\\)', '', ret)\n",
    "    ret = re.sub('\"','', ret)\n",
    "    ret = re.sub(r\"'s\\b\",\"\", ret)\n",
    "    ret = re.sub(\"[^a-zA-Z]\", \" \", ret) \n",
    "    \n",
    "    #Remove any words shorter than 2 letters\n",
    "    tokens = [w for w in ret.split() if not w in stop]\n",
    "    long_words=[]\n",
    "    for i in tokens:\n",
    "        if len(i)>=3:                 \n",
    "            long_words.append(i)   \n",
    "    return (\" \".join(long_words)).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29acb064",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading Data\n",
    "data = pd.read_csv('data/cleaned_data.csv')\n",
    "data = data[['Summary', 'Text']]\n",
    "\n",
    "#Create corpus for TF-IDF of summaries\n",
    "corpus = data[\"Text\"]\n",
    "corpus = corpus.apply(clean_text)\n",
    "\n",
    "#Create Sample Text Doc\n",
    "test = data['Text'][0]\n",
    "text = test.replace('\\\\', '').replace('/', '').replace('.,', '.').replace('.;,', '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9d05f266",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = data['Text'][0]\n",
    "label = data['Summary'][0]\n",
    "text = test.replace('\\\\', '').replace('/', '').replace('.,', '.').replace('.;,', '.')\n",
    "lbl = label.replace('\\\\', '').replace('/', '').replace('.,', '. ').replace('.;,', '. ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d98e11b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = sent_tokenize(text)\n",
    "clean = []\n",
    "for sen in sentence:\n",
    "    clean.append(clean_text(sen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9fd8b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Word2Vec\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "words = []\n",
    "all_words = [i.split() for i in clean]\n",
    "model = Word2Vec(all_words, min_count=1, vector_size=300)\n",
    "\n",
    "sent_vector=[]\n",
    "for i in clean:\n",
    "    plus=0\n",
    "    for j in i.split():\n",
    "        plus+= model.wv[j]\n",
    "    plus = plus/len(i.split())\n",
    "    sent_vector.append(plus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3e71ed",
   "metadata": {},
   "source": [
    "The choice of using 6 clusters comes from the average length of the summaries. We cannot tune this parameter because it directly affects our ROUGE-1 score, i.e. larger summaries increase the likelihood of overlap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b57e8e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean each night. Endeavor to leave the workspace in a way that you can sit down the next day and start working immediately, without having to do any work or tidying.Even if the rest of your studio is a bit disorganized, an organized workspace will help you get down to business every time you want to make art. You can even use it for smaller areas. Once a month, do a purge of your studio. Artists are constantly making new things, experimenting, and making a mess. Toss it. \n"
     ]
    }
   ],
   "source": [
    "#Performing KMeans with 5 Clusters\n",
    "n_clusters = 6\n",
    "kmeans = KMeans(n_clusters, init = 'k-means++', random_state = 42)\n",
    "y_kmeans = kmeans.fit_predict(sent_vector)\n",
    "\n",
    "my_list=[]\n",
    "for i in range(n_clusters):\n",
    "    my_dict={}\n",
    "    \n",
    "    for j in range(len(y_kmeans)):\n",
    "        \n",
    "        if y_kmeans[j]==i:\n",
    "            my_dict[j] = distance.euclidean(kmeans.cluster_centers_[i],sent_vector[j])\n",
    "    min_distance = min(my_dict.values())\n",
    "    my_list.append(min(my_dict, key=my_dict.get))\n",
    "\n",
    "result = \"\"\n",
    "for i in sorted(my_list):\n",
    "    result += sentence[i] + \" \"\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83ae928",
   "metadata": {},
   "source": [
    "# Scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6610af0a",
   "metadata": {},
   "source": [
    "For scoring, I first extract the keywords in the output from KMeans and the human-written summary (the label). Then I look at the overlap of those keywords to determine how many match -- this will give us an accuracy and precision score, and thus an F1 score. I will also calculate the ROUGE1 score between both the concatenated list of keywords and the summaries themselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ee14b2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TF_IDF():\n",
    "    def __init__(self, corpus):\n",
    "        self.text = corpus\n",
    "        self.stopwords = set(stopwords.words(\"english\"))\n",
    "        self.cv = CountVectorizer(max_df=0.85, stop_words=self.stopwords)\n",
    "        self.wordcount = self.cv.fit_transform(corpus)\n",
    "    \n",
    "        self.transformer = TfidfTransformer(smooth_idf=True, use_idf=True)\n",
    "        self.transformer.fit(self.wordcount)\n",
    "    \n",
    "    def sort_vals(self, matrix):\n",
    "        tuples = zip(matrix.col, matrix.data)\n",
    "        return sorted(tuples, key=lambda x: (x[1], x[0]), reverse=True)\n",
    "    \n",
    "    def extract_top_k(self, feature_names, items, k=10):\n",
    "        items = items[:k]\n",
    "\n",
    "        scores = []\n",
    "        features = []\n",
    "\n",
    "        for idx, score in items:\n",
    "            scores.append(round(score, 3))\n",
    "            features.append(feature_names[idx])\n",
    "        \n",
    "        results = {}\n",
    "        for idx in range(len(features)):\n",
    "            results[features[idx]] = scores[idx]\n",
    "        \n",
    "        return results\n",
    "\n",
    "    def extract_keywords(self, doc, k=10):\n",
    "        feature_names = self.cv.get_feature_names()\n",
    "        tf_idf_vector = self.transformer.transform(self.cv.transform([doc]))\n",
    "\n",
    "        sort_items = self.sort_vals(tf_idf_vector.tocoo())\n",
    "        keywords = self.extract_top_k(feature_names, sort_items, k)\n",
    "\n",
    "        print(\"\\nDocument\")\n",
    "        print(doc)\n",
    "        print(\"\\nKeywords\")\n",
    "        for k in keywords:\n",
    "            print(k, keywords[k])\n",
    "        \n",
    "        return keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f280bb2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/psicurello/Library/Python/3.8/lib/python/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Document\n",
      "clean each night. Endeavor to leave the workspace in a way that you can sit down the next day and start working immediately, without having to do any work or tidying.Even if the rest of your studio is a bit disorganized, an organized workspace will help you get down to business every time you want to make art. You can even use it for smaller areas. Once a month, do a purge of your studio. Artists are constantly making new things, experimenting, and making a mess. Toss it. \n",
      "\n",
      "Keywords\n",
      "workspace 0.42\n",
      "studio 0.385\n",
      "tidying 0.252\n",
      "purge 0.245\n",
      "disorganized 0.233\n",
      "endeavor 0.223\n",
      "experimenting 0.205\n",
      "artists 0.179\n",
      "making 0.166\n",
      "toss 0.163\n",
      "\n",
      "Document\n",
      "Keep related supplies in the same area. Make an effort to clean a dedicated workspace after every session. Place loose supplies in large, clearly visible containers. Use clotheslines and clips to hang sketches, photos, and reference material. Use every inch of the room for storage, especially vertical space. Use chalkboard paint to make space for drafting ideas right on the walls. Purchase a label maker to make your organization strategy semi-permanent. Make a habit of throwing out old, excess, or useless stuff each month.\n",
      "\n",
      "Keywords\n",
      "clotheslines 0.289\n",
      "supplies 0.26\n",
      "chalkboard 0.217\n",
      "sketches 0.201\n",
      "workspace 0.184\n",
      "space 0.181\n",
      "drafting 0.18\n",
      "useless 0.175\n",
      "maker 0.17\n",
      "make 0.165\n"
     ]
    }
   ],
   "source": [
    "tf = TF_IDF(corpus)\n",
    "res_keyword = tf.extract_keywords(result, 10)\n",
    "lbl_keyword = tf.extract_keywords(lbl, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ae9d1070",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rougeL'], use_stemmer=True)\n",
    "scores = scorer.score(result,\n",
    "                      label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "056b8da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean each night. Endeavor to leave the workspace in a way that you can sit down the next day and start working immediately, without having to do any work or tidying.Even if the rest of your studio is a bit disorganized, an organized workspace will help you get down to business every time you want to make art. You can even use it for smaller areas. Once a month, do a purge of your studio. Artists are constantly making new things, experimenting, and making a mess. Toss it. \n",
      "\n",
      "\n",
      "Keep related supplies in the same area. Make an effort to clean a dedicated workspace after every session. Place loose supplies in large, clearly visible containers. Use clotheslines and clips to hang sketches, photos, and reference material. Use every inch of the room for storage, especially vertical space. Use chalkboard paint to make space for drafting ideas right on the walls. Purchase a label maker to make your organization strategy semi-permanent. Make a habit of throwing out old, excess, or useless stuff each month.\n"
     ]
    }
   ],
   "source": [
    "print(result)\n",
    "print(\"\\n\")\n",
    "print(lbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "482e146d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': Score(precision=0.35294117647058826, recall=0.33707865168539325, fmeasure=0.3448275862068966),\n",
       " 'rougeL': Score(precision=0.16470588235294117, recall=0.15730337078651685, fmeasure=0.16091954022988506)}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc2a391",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
